problem:
  small:
    num_gates: 20
    num_qpus: 3
    num_qubits: 12
    qpu_capacity: 5
    time_horizon: 30

model:
  hidden_dim: 128
  num_layers: 3
  num_bases: 8
  dropout: 0.1
  num_heads: 4

ppo:
  learning_rate: 1e-5
  gamma: 0.99
  gae_lambda: 0.95
  clip_epsilon: 0.2
  value_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 0.5
  rollout_length: 128 
  minibatch_size: 32
  num_epochs: 4  

imitation_learning:
  bc_pretrain_epochs: 50  
  bc_pretrain_batch_size: 64  
  bc_pretrain_lr: 1e-3
  
  expert_buffer_size: 5000
  
  initial_expert_prob: 0.8
  final_expert_prob: 0.3
  
  reward_weights:
    r_colocate: 5.0
    r_separate: 3.0
    r_completion: 30.0
    r_expert_match: 10.0
    r_step: 0.0001
    w_alloc: 2.0
    w_schedule: 1.0
    w_progress: 0.001

training:
  stage1:
    episodes: 30 
    test_frequency: 10
    
  stage2:
    timesteps: 10000  
    log_frequency: 20